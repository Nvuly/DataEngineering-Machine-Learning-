{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #ì •ê·œ í‘œí˜„ì‹\n",
    "import nltk #ìì—°ì–´ì²˜ë¦¬\n",
    "from nltk.corpus import stopwords #ë¶ˆìš©ì–´ì²˜ë¦¬\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ë°ì´í„°í”„ë ˆì„ í™•ì¸ : \n",
      "                                                     text        class\n",
      "2       Ex Wife Threatening SuicideRecently I left my ...      suicide\n",
      "3       Am I weird I don't get affected by compliments...  non-suicide\n",
      "4       Finally 2020 is almost over... So I can never ...  non-suicide\n",
      "8               i need helpjust help me im crying so hard      suicide\n",
      "9       Iâ€™m so lostHello, my name is Adam (16) and Iâ€™v...      suicide\n",
      "...                                                   ...          ...\n",
      "348103  If you don't like rock then your not going to ...  non-suicide\n",
      "348106  You how you can tell i have so many friends an...  non-suicide\n",
      "348107  pee probably tastes like salty teağŸ˜ğŸ’¦â€¼ï¸ can som...  non-suicide\n",
      "348108  The usual stuff you find hereI'm not posting t...      suicide\n",
      "348110  I still haven't beaten the first boss in Hollo...  non-suicide\n",
      "\n",
      "[232074 rows x 2 columns]\n",
      "********************************************************************************\n",
      "ê¸°ë³¸ ì •ë³´ í™•ì¸í•˜ê¸°\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 232074 entries, 2 to 348110\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    232074 non-null  object\n",
      " 1   class   232074 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "file_path = 'D:\\Code\\ìš°ìš¸ì¦ ì˜ˆì¸¡(í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸)/Suicide_Detection.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "print(f'ì „ì²´ ë°ì´í„°í”„ë ˆì„ í™•ì¸ : \\n{df}')\n",
    "\n",
    "print('*'*80)\n",
    "\n",
    "print('ê¸°ë³¸ ì •ë³´ í™•ì¸í•˜ê¸°')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\human\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\human\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') ##ë¬¸ì¥ë¶€í˜¸\n",
    "nltk.download('stopwords') ##ë¶ˆìš©ì–´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì „ì²˜ë¦¬ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "def preprocessing(text, remove_stopwords = False) : \n",
    "    # ë¶ˆìš©ì–´ ì œê±°ëŠ” ì˜µì…˜ìœ¼ë¡œ\n",
    "    # 1. ì˜ì–´ ì•ŒíŒŒë²³ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë¬¸ì, ê³µë°±, ìˆ«ì ë“±ì„ ê³µë°±(' ')ìœ¼ë¡œ ëŒ€ì²´\n",
    "    text = re.sub('[^a-zA-Z]',' ', text) \n",
    "    #ë¬¸ìì—´ì¹˜í™˜ : re.sub(pattern, replace, text), text ì¤‘ patternì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì„ replaceë¡œ ëŒ€ì²´í•œë‹¤.\n",
    "    # 2. ëŒ€ë¬¸ì --> ì†Œë¬¸ìë¡œ ë³€í™˜ + nltk.word_tokenize() í•¨ìˆ˜ë¡œ í† í°í™”\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    # 3. ë¶ˆìš©ì–´ ì œê±°\n",
    "    if remove_stopwords : \n",
    "        # ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        # ë¶ˆìš©ì–´ê°€ ì•„ë‹Œ ë‹¨ì–´(í† í°)ë“¤ë¡œ ì´ë£¨ì–´ì§„ ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "        clean_words = []\n",
    "        for word in words :\n",
    "            if word not in stopwords_list :\n",
    "                clean_words.append(word)\n",
    "                # join(list --> str ë¬¸ì¥ ë¶™ì´ê¸°) ë¶ˆìš©ì–´ ì œê±°\n",
    "                clean_text = ' '.join(clean_words)\n",
    "    else :\n",
    "        # join(list --> str ë¬¸ì¥ ë¶™ì´ê¸°) ë¶ˆìš©ì–´ í¬í•¨\n",
    "        clean_texts = ' '.join(words)\n",
    "    return clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, remove_stopwords = False) :\n",
    "    text = re.sub('a-zA-z', ' ', text)\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    \n",
    "    if remove_stopwords :\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        clean_words = []\n",
    "        for word in words :\n",
    "            if word not in stopwords_list :\n",
    "                clean_words.append(word)\n",
    "                clean_text = ' '.join(clean_words)\n",
    "    else :\n",
    "        clean_texts = ' '.join(words)\n",
    "    return clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n- í•¨ìˆ˜ ì •ì˜\\n\\n`def` í•¨ìˆ˜ë¥¼ ì •ì˜ , text ë³€ìˆ˜ì— `re.sub` ì‚¬ìš©í•´ ì˜ì–´ ì•ŒíŒŒë²³ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ë¥¼ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´ í•©ë‹ˆë‹¤.\\n\\n- í† í°í™”\\n\\nwords ë³€ìˆ˜ì— `nltk.word_tokenized(text.lower())` ëŒ€ë¬¸ìë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜ í•˜ë©´ì„œ í† í°í™”ë¥¼ ì§„í–‰ í•©ë‹ˆë‹¤.\\n\\n- ë¶ˆìš©ì–´\\n\\nstopwords_list ë³€ìˆ˜ì— `stopowrds.words(â€™englishâ€™)` ì‚¬ìš©í•´ ë¶ˆìš©ì–´ë¥¼ ìƒì„±í•˜ê³ , `for`ì´ìš©í•´ í† í°í™”ë¥¼ í–ˆë˜ words ë³€ìˆ˜ë¥¼ word ë³€ìˆ˜ì— ë‹´ì•„ì„œ `if`(True, False) ì´ìš©í•´ ë¶ˆìš©ì–´ê°€ ì—†ëŠ” í† í°í™”ëŠ” `clean_words.append(word)` clean_words ë³€ìˆ˜ì— ë„£ìŠµë‹ˆë‹¤.\\n\\n- í† í°í™” â€”> ë¬¸ìì—´ ë³€í™˜\\n\\nclean_text ë³€ìˆ˜ì— ë¶ˆìš©ì–´ê°€ ì œê±°í•˜ê³  ë¬¸ìì—´ë¡œ ë¶™ì¼ ë•Œ `' '.join(clean_words)` ì‚¬ìš© í•©ë‹ˆë‹¤.\\n\\në¶ˆìš©ì–´ë¥¼ ì œê±° í•˜ì§€ ì•Šê³  ë¬¸ìì—´ë¡œ ë¶™ì¼ ë•Œ\\n\\n`' '.join(words)` ì‚¬ìš© í•©ë‹ˆë‹¤.\\n\\n`return` ìœ¼ë¡œ clean_text ë³€ìˆ˜ë¥¼ ë°˜í™˜ í•©ë‹ˆë‹¤.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "`def` í•¨ìˆ˜ë¥¼ ì •ì˜ , text ë³€ìˆ˜ì— `re.sub` ì‚¬ìš©í•´ ì˜ì–´ ì•ŒíŒŒë²³ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ë¥¼ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- í† í°í™”\n",
    "\n",
    "words ë³€ìˆ˜ì— `nltk.word_tokenized(text.lower())` ëŒ€ë¬¸ìë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜ í•˜ë©´ì„œ í† í°í™”ë¥¼ ì§„í–‰ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ë¶ˆìš©ì–´\n",
    "\n",
    "stopwords_list ë³€ìˆ˜ì— `stopowrds.words(â€™englishâ€™)` ì‚¬ìš©í•´ ë¶ˆìš©ì–´ë¥¼ ìƒì„±í•˜ê³ , `for`ì´ìš©í•´ í† í°í™”ë¥¼ í–ˆë˜ words ë³€ìˆ˜ë¥¼ word ë³€ìˆ˜ì— ë‹´ì•„ì„œ `if`(True, False) ì´ìš©í•´ ë¶ˆìš©ì–´ê°€ ì—†ëŠ” í† í°í™”ëŠ” `clean_words.append(word)` clean_words ë³€ìˆ˜ì— ë„£ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- í† í°í™” â€”> ë¬¸ìì—´ ë³€í™˜\n",
    "\n",
    "clean_text ë³€ìˆ˜ì— ë¶ˆìš©ì–´ê°€ ì œê±°í•˜ê³  ë¬¸ìì—´ë¡œ ë¶™ì¼ ë•Œ `' '.join(clean_words)` ì‚¬ìš© í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë¶ˆìš©ì–´ë¥¼ ì œê±° í•˜ì§€ ì•Šê³  ë¬¸ìì—´ë¡œ ë¶™ì¼ ë•Œ\n",
    "\n",
    "`' '.join(words)` ì‚¬ìš© í•©ë‹ˆë‹¤.\n",
    "\n",
    "`return` ìœ¼ë¡œ clean_text ë³€ìˆ˜ë¥¼ ë°˜í™˜ í•©ë‹ˆë‹¤.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'clean_texts' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# text ì»¬ëŸ¼ì— ëŒ€í•´ì„œ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì‹¤í–‰\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m clean_texts \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : preprocessing(x, remove_stopwords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;66;03m#####\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(clean_texts)\n",
      "File \u001b[1;32mc:\\Users\\human\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\human\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\human\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\human\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# text ì»¬ëŸ¼ì— ëŒ€í•´ì„œ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì‹¤í–‰\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m clean_texts \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : preprocessing(x, remove_stopwords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;66;03m#####\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(clean_texts)\n",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m, in \u001b[0;36mpreprocessing\u001b[1;34m(text, remove_stopwords)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[0;32m     13\u001b[0m     clean_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(words)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_texts\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'clean_texts' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# text ì»¬ëŸ¼ì— ëŒ€í•´ì„œ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì‹¤í–‰\n",
    "clean_texts = df.text.apply(lambda x : preprocessing(x, remove_stopwords=True)) #####\n",
    "\n",
    "print(clean_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text        label\n",
      "2       Ex Wife Threatening SuicideRecently I left my ...      suicide\n",
      "3       Am I weird I don't get affected by compliments...  non-suicide\n",
      "4       Finally 2020 is almost over... So I can never ...  non-suicide\n",
      "8               i need helpjust help me im crying so hard      suicide\n",
      "9       Iâ€™m so lostHello, my name is Adam (16) and Iâ€™v...      suicide\n",
      "...                                                   ...          ...\n",
      "348103  If you don't like rock then your not going to ...  non-suicide\n",
      "348106  You how you can tell i have so many friends an...  non-suicide\n",
      "348107  pee probably tastes like salty teağŸ˜ğŸ’¦â€¼ï¸ can som...  non-suicide\n",
      "348108  The usual stuff you find hereI'm not posting t...      suicide\n",
      "348110  I still haven't beaten the first boss in Hollo...  non-suicide\n",
      "\n",
      "[232074 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# class ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½\n",
    "df.rename(columns = {'class':'label'}, inplace = True)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rollbackTarget",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
