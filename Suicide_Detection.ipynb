{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #정규 표현식\n",
    "import nltk #자연어처리\n",
    "from nltk.corpus import stopwords #불용어처리\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터프레임 확인 : \n",
      "                                                     text        class\n",
      "2       Ex Wife Threatening SuicideRecently I left my ...      suicide\n",
      "3       Am I weird I don't get affected by compliments...  non-suicide\n",
      "4       Finally 2020 is almost over... So I can never ...  non-suicide\n",
      "8               i need helpjust help me im crying so hard      suicide\n",
      "9       I’m so lostHello, my name is Adam (16) and I’v...      suicide\n",
      "...                                                   ...          ...\n",
      "348103  If you don't like rock then your not going to ...  non-suicide\n",
      "348106  You how you can tell i have so many friends an...  non-suicide\n",
      "348107  pee probably tastes like salty tea😏💦‼️ can som...  non-suicide\n",
      "348108  The usual stuff you find hereI'm not posting t...      suicide\n",
      "348110  I still haven't beaten the first boss in Hollo...  non-suicide\n",
      "\n",
      "[232074 rows x 2 columns]\n",
      "********************************************************************************\n",
      "기본 정보 확인하기\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 232074 entries, 2 to 348110\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    232074 non-null  object\n",
      " 1   class   232074 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "file_path = 'D:\\Code\\우울증 예측(텍스트 분류 모델)/Suicide_Detection.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "print(f'전체 데이터프레임 확인 : \\n{df}')\n",
    "\n",
    "print('*'*80)\n",
    "\n",
    "print('기본 정보 확인하기')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\human\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\human\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') ##문장부호\n",
    "nltk.download('stopwords') ##불용어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수 정의\n",
    "\n",
    "def preprocessing(text, remove_stopwords = False) : \n",
    "    # 불용어 제거는 옵션으로\n",
    "    # 1. 영어 알파벳을 제외한 나머지 문자, 공백, 숫자 등을 공백(' ')으로 대체\n",
    "    text = re.sub('[^a-zA-Z]',' ', text) \n",
    "    #문자열치환 : re.sub(pattern, replace, text), text 중 pattern에 해당하는 부분을 replace로 대체한다.\n",
    "    # 2. 대문자 --> 소문자로 변환 + nltk.word_tokenize() 함수로 토큰화\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    # 3. 불용어 제거\n",
    "    if remove_stopwords : \n",
    "        # 불용어 리스트 생성\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        # 불용어가 아닌 단어(토큰)들로 이루어진 새로운 리스트 생성\n",
    "        clean_words = []\n",
    "        for word in words :\n",
    "            if word not in stopwords_list :\n",
    "                clean_words.append(word)\n",
    "                # join(list --> str 문장 붙이기) 불용어 제거\n",
    "                clean_text = ' '.join(clean_words)\n",
    "    else :\n",
    "        # join(list --> str 문장 붙이기) 불용어 포함\n",
    "        clean_texts = ' '.join(words)\n",
    "    return clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, remove_stopwords = False) :\n",
    "    text = re.sub('a-zA-z', ' ', text)\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    \n",
    "    if remove_stopwords :\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        clean_words = []\n",
    "        for word in words :\n",
    "            if word not in stopwords_list :\n",
    "                clean_words.append(word)\n",
    "                clean_text = ' '.join(clean_words)\n",
    "    else :\n",
    "        clean_texts = ' '.join(words)\n",
    "    return clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n- 함수 정의\\n\\n`def` 함수를 정의 , text 변수에 `re.sub` 사용해 영어 알파벳을 제외한 나머지를 공백으로 대체 합니다.\\n\\n- 토큰화\\n\\nwords 변수에 `nltk.word_tokenized(text.lower())` 대문자를 소문자로 변환 하면서 토큰화를 진행 합니다.\\n\\n- 불용어\\n\\nstopwords_list 변수에 `stopowrds.words(’english’)` 사용해 불용어를 생성하고, `for`이용해 토큰화를 했던 words 변수를 word 변수에 담아서 `if`(True, False) 이용해 불용어가 없는 토큰화는 `clean_words.append(word)` clean_words 변수에 넣습니다.\\n\\n- 토큰화 —> 문자열 변환\\n\\nclean_text 변수에 불용어가 제거하고 문자열로 붙일 때 `' '.join(clean_words)` 사용 합니다.\\n\\n불용어를 제거 하지 않고 문자열로 붙일 때\\n\\n`' '.join(words)` 사용 합니다.\\n\\n`return` 으로 clean_text 변수를 반환 합니다.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- 함수 정의\n",
    "\n",
    "`def` 함수를 정의 , text 변수에 `re.sub` 사용해 영어 알파벳을 제외한 나머지를 공백으로 대체 합니다.\n",
    "\n",
    "- 토큰화\n",
    "\n",
    "words 변수에 `nltk.word_tokenized(text.lower())` 대문자를 소문자로 변환 하면서 토큰화를 진행 합니다.\n",
    "\n",
    "- 불용어\n",
    "\n",
    "stopwords_list 변수에 `stopowrds.words(’english’)` 사용해 불용어를 생성하고, `for`이용해 토큰화를 했던 words 변수를 word 변수에 담아서 `if`(True, False) 이용해 불용어가 없는 토큰화는 `clean_words.append(word)` clean_words 변수에 넣습니다.\n",
    "\n",
    "- 토큰화 —> 문자열 변환\n",
    "\n",
    "clean_text 변수에 불용어가 제거하고 문자열로 붙일 때 `' '.join(clean_words)` 사용 합니다.\n",
    "\n",
    "불용어를 제거 하지 않고 문자열로 붙일 때\n",
    "\n",
    "`' '.join(words)` 사용 합니다.\n",
    "\n",
    "`return` 으로 clean_text 변수를 반환 합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'clean_texts' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# text 컬럼에 대해서 전처리 함수 실행\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m clean_texts \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : preprocessing(x, remove_stopwords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;66;03m#####\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(clean_texts)\n",
      "File \u001b[1;32mc:\\Users\\human\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\human\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\human\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\human\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# text 컬럼에 대해서 전처리 함수 실행\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m clean_texts \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : preprocessing(x, remove_stopwords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;66;03m#####\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(clean_texts)\n",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m, in \u001b[0;36mpreprocessing\u001b[1;34m(text, remove_stopwords)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[0;32m     13\u001b[0m     clean_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(words)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_texts\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'clean_texts' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# text 컬럼에 대해서 전처리 함수 실행\n",
    "clean_texts = df.text.apply(lambda x : preprocessing(x, remove_stopwords=True)) #####\n",
    "\n",
    "print(clean_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text        label\n",
      "2       Ex Wife Threatening SuicideRecently I left my ...      suicide\n",
      "3       Am I weird I don't get affected by compliments...  non-suicide\n",
      "4       Finally 2020 is almost over... So I can never ...  non-suicide\n",
      "8               i need helpjust help me im crying so hard      suicide\n",
      "9       I’m so lostHello, my name is Adam (16) and I’v...      suicide\n",
      "...                                                   ...          ...\n",
      "348103  If you don't like rock then your not going to ...  non-suicide\n",
      "348106  You how you can tell i have so many friends an...  non-suicide\n",
      "348107  pee probably tastes like salty tea😏💦‼️ can som...  non-suicide\n",
      "348108  The usual stuff you find hereI'm not posting t...      suicide\n",
      "348110  I still haven't beaten the first boss in Hollo...  non-suicide\n",
      "\n",
      "[232074 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# class 컬럼 이름 변경\n",
    "df.rename(columns = {'class':'label'}, inplace = True)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rollbackTarget",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
