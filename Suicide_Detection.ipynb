{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #ì •ê·œ í‘œí˜„ì‹\n",
    "import nltk #ìì—°ì–´ì²˜ë¦¬\n",
    "from nltk.corpus import stopwords #ë¶ˆìš©ì–´ì²˜ë¦¬\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ë°ì´í„°í”„ë ˆì„ í™•ì¸ : \n",
      "        Unnamed: 0                                               text  \\\n",
      "0                2  Ex Wife Threatening SuicideRecently I left my ...   \n",
      "1                3  Am I weird I don't get affected by compliments...   \n",
      "2                4  Finally 2020 is almost over... So I can never ...   \n",
      "3                8          i need helpjust help me im crying so hard   \n",
      "4                9  Iâ€™m so lostHello, my name is Adam (16) and Iâ€™v...   \n",
      "...            ...                                                ...   \n",
      "232069      348103  If you don't like rock then your not going to ...   \n",
      "232070      348106  You how you can tell i have so many friends an...   \n",
      "232071      348107  pee probably tastes like salty teağŸ˜ğŸ’¦â€¼ï¸ can som...   \n",
      "232072      348108  The usual stuff you find hereI'm not posting t...   \n",
      "232073      348110  I still haven't beaten the first boss in Hollo...   \n",
      "\n",
      "              class  \n",
      "0           suicide  \n",
      "1       non-suicide  \n",
      "2       non-suicide  \n",
      "3           suicide  \n",
      "4           suicide  \n",
      "...             ...  \n",
      "232069  non-suicide  \n",
      "232070  non-suicide  \n",
      "232071  non-suicide  \n",
      "232072      suicide  \n",
      "232073  non-suicide  \n",
      "\n",
      "[232074 rows x 3 columns]\n",
      "********************************************************************************\n",
      "ê¸°ë³¸ ì •ë³´ í™•ì¸í•˜ê¸°\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232074 entries, 0 to 232073\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  232074 non-null  int64 \n",
      " 1   text        232074 non-null  object\n",
      " 2   class       232074 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "file_path = 'D:\\Code\\ìš°ìš¸ì¦ ì˜ˆì¸¡(í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸)/Suicide_Detection.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f'ì „ì²´ ë°ì´í„°í”„ë ˆì„ í™•ì¸ : \\n{df}')\n",
    "\n",
    "print('*'*80)\n",
    "\n",
    "print('ê¸°ë³¸ ì •ë³´ í™•ì¸í•˜ê¸°')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt') ##ë¬¸ì¥ë¶€í˜¸\n",
    "nltk.download('stopwords') ##ë¶ˆìš©ì–´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì „ì²˜ë¦¬ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "def preprocessing(text, remove_stopwords = False) : \n",
    "    # ë¶ˆìš©ì–´ ì œê±°ëŠ” ì˜µì…˜ìœ¼ë¡œ\n",
    "    # 1. ì˜ì–´ ì•ŒíŒŒë²³ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë¬¸ì, ê³µë°±, ìˆ«ì ë“±ì„ ê³µë°±(' ')ìœ¼ë¡œ ëŒ€ì²´\n",
    "    text = re.sub('[^a-zA-Z]',' ', text) \n",
    "    #ë¬¸ìì—´ì¹˜í™˜ : re.sub(pattern, replace, text), text ì¤‘ patternì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì„ replaceë¡œ ëŒ€ì²´í•œë‹¤.\n",
    "    # 2. ëŒ€ë¬¸ì --> ì†Œë¬¸ìë¡œ ë³€í™˜ + nltk.word_tokenize() í•¨ìˆ˜ë¡œ í† í°í™”\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    # 3. ë¶ˆìš©ì–´ ì œê±°\n",
    "    if remove_stopwords : \n",
    "        # ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        # ë¶ˆìš©ì–´ê°€ ì•„ë‹Œ ë‹¨ì–´(í† í°)ë“¤ë¡œ ì´ë£¨ì–´ì§„ ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "        clean_words = []\n",
    "        for word in words :\n",
    "            if word not in stopwords_list :\n",
    "                clean_words.append(word)\n",
    "                # join(list --> str ë¬¸ì¥ ë¶™ì´ê¸°) ë¶ˆìš©ì–´ ì œê±°\n",
    "                clean_text = ' '.join(clean_words)\n",
    "    else :\n",
    "        # join(list --> str ë¬¸ì¥ ë¶™ì´ê¸°) ë¶ˆìš©ì–´ í¬í•¨\n",
    "        clean_text = ' '.join(words)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "`def` í•¨ìˆ˜ë¥¼ ì •ì˜ , text ë³€ìˆ˜ì— `re.sub` ì‚¬ìš©í•´ ì˜ì–´ ì•ŒíŒŒë²³ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ë¥¼ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- í† í°í™”\n",
    "\n",
    "words ë³€ìˆ˜ì— `nltk.word_tokenized(text.lower())` ëŒ€ë¬¸ìë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜ í•˜ë©´ì„œ í† í°í™”ë¥¼ ì§„í–‰ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ë¶ˆìš©ì–´\n",
    "\n",
    "stopwords_list ë³€ìˆ˜ì— `stopowrds.words(â€™englishâ€™)` ì‚¬ìš©í•´ ë¶ˆìš©ì–´ë¥¼ ìƒì„±í•˜ê³ , `for`ì´ìš©í•´ í† í°í™”ë¥¼ í–ˆë˜ words ë³€ìˆ˜ë¥¼ word ë³€ìˆ˜ì— ë‹´ì•„ì„œ `if`(True, False) ì´ìš©í•´ ë¶ˆìš©ì–´ê°€ ì—†ëŠ” í† í°í™”ëŠ” `clean_words.append(word)` clean_words ë³€ìˆ˜ì— ë„£ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- í† í°í™” â€”> ë¬¸ìì—´ ë³€í™˜\n",
    "\n",
    "clean_text ë³€ìˆ˜ì— ë¶ˆìš©ì–´ê°€ ì œê±°í•˜ê³  ë¬¸ìì—´ë¡œ ë¶™ì¼ ë•Œ `' '.join(clean_words)` ì‚¬ìš© í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë¶ˆìš©ì–´ë¥¼ ì œê±° í•˜ì§€ ì•Šê³  ë¬¸ìì—´ë¡œ ë¶™ì¼ ë•Œ\n",
    "\n",
    "`' '.join(words)` ì‚¬ìš© í•©ë‹ˆë‹¤.\n",
    "\n",
    "`return` ìœ¼ë¡œ clean_text ë³€ìˆ˜ë¥¼ ë°˜í™˜ í•©ë‹ˆë‹¤.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text ì»¬ëŸ¼ì— ëŒ€í•´ì„œ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì‹¤í–‰\n",
    "df.text.apply(lambda x : preprocessing(x, remove_stopword=True)) #####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rollbackTarget",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
